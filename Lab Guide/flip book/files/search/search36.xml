Appendix A: Python Script for PDI :@0.120984:0.057725:0.376176:0.057725:0.376176:0.044612:0.120984:0.044612:0.010737:0.009625:0.009680:0.009235:0.009736:0.009643:0.004265:0.008030:0.004191:0.010737:0.005007:0.004024:0.009662:0.008456:0.006212:0.009513:0.009866:0.009680:0.004191:0.008512:0.007844:0.006472:0.004265:0.009643:0.006212:0.004061:0.005434:0.009866:0.006472:0.004006:0.009662:0.011479:0.004580:0.004191
22 :@0.490744:0.939424:0.513682:0.939424:0.513682:0.926311:0.490744:0.926311:0.009474:0.009272:0.004191
 :@0.120984:0.966790:0.125175:0.966790:0.125175:0.953677:0.120984:0.953677:0.004191
# the following libraries need to be installed (see pre-requisites) :@0.120984:0.099332:0.550118:0.099332:0.550118:0.085553:0.120984:0.085553:0.008874:0.004218:0.005034:0.008466:0.007861:0.004218:0.004823:0.008859:0.003659:0.003613:0.008859:0.010930:0.003598:0.008466:0.008904:0.004188:0.003659:0.003598:0.008889:0.005261:0.007619:0.005427:0.003659:0.007831:0.006410:0.004263:0.008466:0.007861:0.007861:0.008904:0.004188:0.005231:0.008859:0.004233:0.008889:0.007846:0.004218:0.003659:0.008436:0.006410:0.005080:0.007695:0.003598:0.003659:0.007831:0.009019:0.004233:0.004626:0.006410:0.007907:0.007861:0.004218:0.008889:0.005261:0.007875:0.006047:0.005261:0.007846:0.008904:0.008617:0.003659:0.006410:0.003659:0.005201:0.007861:0.006410:0.004707:0.004142
# pandas :@0.120984:0.113586:0.186397:0.113586:0.186397:0.099806:0.120984:0.099806:0.008869:0.004233:0.008889:0.007635:0.008466:0.008904:0.007619:0.006655:0.004142
# matplotlib :@0.120984:0.127696:0.206756:0.127696:0.206756:0.113917:0.120984:0.113917:0.008874:0.004218:0.013092:0.007695:0.005004:0.008889:0.003613:0.008859:0.005049:0.003659:0.003598:0.009079:0.004142
# py4j :@0.120984:0.141949:0.166247:0.141949:0.166247:0.128170:0.120984:0.128170:0.008874:0.004218:0.008889:0.007241:0.008058:0.003840:0.004142
# numpy :@0.120984:0.156202:0.184583:0.156202:0.184583:0.142423:0.120984:0.142423:0.008874:0.004218:0.008466:0.008466:0.013092:0.008889:0.007451:0.004142
# TPOT :@0.120984:0.170456:0.173900:0.170456:0.173900:0.156676:0.120984:0.156676:0.008869:0.004233:0.007861:0.008466:0.011475:0.007870:0.004142
 :@0.120984:0.184566:0.125126:0.184566:0.125126:0.170787:0.120984:0.170787:0.004142
# import required libraries :@0.120984:0.198819:0.300134:0.198819:0.300134:0.185040:0.120984:0.185040:0.008874:0.004218:0.003659:0.013062:0.008889:0.008859:0.005261:0.005004:0.004251:0.005261:0.007846:0.008904:0.008436:0.003659:0.005216:0.007861:0.008854:0.004233:0.003659:0.003598:0.008889:0.005261:0.007801:0.005261:0.003613:0.007861:0.006717:0.004142
import pandas as pd :@0.120984:0.213073:0.262390:0.213073:0.262390:0.199293:0.120984:0.199293:0.003659:0.013062:0.008889:0.008859:0.005261:0.005004:0.004218:0.008889:0.007635:0.008466:0.008904:0.007619:0.006410:0.004263:0.007695:0.006410:0.004218:0.008889:0.008913:0.004142
import numpy as np :@0.120984:0.227326:0.260173:0.227326:0.260173:0.213546:0.120984:0.213546:0.003659:0.013062:0.008889:0.008859:0.005261:0.005004:0.004218:0.008466:0.008466:0.013092:0.008889:0.007241:0.004218:0.007695:0.006410:0.004218:0.008466:0.008933:0.004142
 :@0.120984:0.241436:0.125126:0.241436:0.125126:0.227657:0.120984:0.227657:0.004142
from tpot import TPOTClassifier :@0.120984:0.255689:0.336619:0.255689:0.336619:0.241910:0.120984:0.241910:0.004823:0.005261:0.008859:0.013077:0.004263:0.005034:0.008889:0.008859:0.005034:0.004218:0.003659:0.013062:0.008889:0.008859:0.005261:0.005004:0.004218:0.007861:0.008466:0.011475:0.007861:0.009267:0.003659:0.007635:0.006410:0.006470:0.003659:0.004792:0.003432:0.007861:0.005375:0.004142
from sklearn import preprocessing :@0.120984:0.269943:0.355164:0.269943:0.355164:0.256163:0.120984:0.256163:0.004823:0.005261:0.008859:0.013077:0.004036:0.006410:0.007514:0.003613:0.007861:0.007695:0.005201:0.008466:0.004218:0.003659:0.013062:0.008889:0.008859:0.005261:0.005004:0.004218:0.008889:0.005261:0.007816:0.008889:0.005261:0.008859:0.006984:0.007907:0.006410:0.006470:0.003659:0.008436:0.009210:0.004142
from sklearn.model_selection import train_test_split :@0.120984:0.284196:0.467473:0.284196:0.467473:0.270416:0.120984:0.270416:0.004823:0.005261:0.008859:0.013077:0.004036:0.006410:0.007514:0.003613:0.007861:0.007695:0.005201:0.008466:0.003220:0.013092:0.008859:0.008904:0.007831:0.003659:0.006213:0.006410:0.008088:0.003659:0.007831:0.007045:0.005034:0.003659:0.008859:0.008451:0.004218:0.003810:0.013092:0.008889:0.008859:0.005261:0.005004:0.004218:0.005034:0.005261:0.007635:0.003659:0.008436:0.006440:0.005034:0.007861:0.006410:0.005080:0.006274:0.006410:0.008889:0.003659:0.003779:0.005505:0.004142
 :@0.120984:0.298342:0.125126:0.298342:0.125126:0.284563:0.120984:0.284563:0.004142
# the dataset is referenced in the step: sv-change_to_numbers :@0.120984:0.312595:0.538023:0.312595:0.538023:0.298816:0.120984:0.298816:0.008874:0.004218:0.005034:0.008466:0.007861:0.004218:0.008904:0.007619:0.005034:0.007695:0.006410:0.008058:0.005034:0.004218:0.003659:0.006484:0.004233:0.005261:0.007846:0.004823:0.007861:0.005261:0.007846:0.008466:0.007045:0.007861:0.008935:0.004233:0.003659:0.008436:0.004218:0.005231:0.008466:0.007861:0.004218:0.006410:0.005080:0.007861:0.008909:0.003225:0.004233:0.006450:0.007257:0.006047:0.007045:0.008466:0.007695:0.008436:0.008904:0.008012:0.006274:0.005019:0.008859:0.006440:0.008466:0.008466:0.013092:0.008889:0.007846:0.005427:0.006539:0.004142
# independent variables (x) are referenced starting at row 1: col 1. -1 references all columns apart from the last :@0.120984:0.326848:0.860421:0.326848:0.860421:0.313069:0.120984:0.313069:0.008874:0.004218:0.003659:0.008436:0.008904:0.007831:0.008889:0.008028:0.008466:0.008904:0.007831:0.008647:0.005034:0.004218:0.007241:0.007695:0.005261:0.003583:0.007695:0.008829:0.003659:0.007831:0.006410:0.004263:0.004626:0.006848:0.004771:0.004233:0.007695:0.005201:0.007861:0.004218:0.005261:0.007846:0.004823:0.007861:0.005261:0.007846:0.008466:0.007045:0.007861:0.008904:0.004188:0.006410:0.005080:0.007695:0.005201:0.005034:0.003659:0.008617:0.008904:0.004188:0.007695:0.005004:0.004218:0.005261:0.008859:0.010870:0.004218:0.008217:0.003220:0.004218:0.007045:0.008859:0.003659:0.004203:0.008058:0.003220:0.004283:0.006047:0.008058:0.004218:0.005261:0.007846:0.004823:0.007861:0.005261:0.007846:0.008491:0.007045:0.007861:0.006410:0.004263:0.007695:0.003598:0.003659:0.004188:0.007045:0.008859:0.003659:0.008451:0.013092:0.008466:0.006410:0.004263:0.007695:0.008829:0.007695:0.005201:0.005034:0.004218:0.004823:0.005261:0.008859:0.013077:0.004218:0.005034:0.008466:0.007861:0.004218:0.003659:0.007635:0.006410:0.005310:0.004142
x = dataset.iloc[:,1:-1].values  :@0.120984:0.341101:0.316260:0.341101:0.316260:0.327322:0.120984:0.327322:0.006848:0.004218:0.010280:0.004218:0.008904:0.007619:0.005034:0.007695:0.006410:0.007907:0.005004:0.003417:0.003659:0.003598:0.008859:0.007045:0.004626:0.003220:0.003304:0.008063:0.003225:0.006249:0.008058:0.004626:0.003220:0.007241:0.007695:0.003613:0.008466:0.007861:0.006410:0.004540:0.004142
 :@0.120984:0.355212:0.125126:0.355212:0.125126:0.341433:0.120984:0.341433:0.004142
# transform features by scaling each feature to a given range:@0.120984:0.369465:0.526038:0.369465:0.526038:0.355686:0.120984:0.355686:0.008869:0.004233:0.005039:0.005261:0.007635:0.008466:0.006410:0.004868:0.008859:0.005261:0.013077:0.004218:0.004823:0.007861:0.007695:0.005004:0.008466:0.005261:0.007846:0.006410:0.004263:0.008889:0.007241:0.004218:0.006410:0.007075:0.007695:0.003598:0.003659:0.008436:0.008904:0.004188:0.007861:0.007695:0.006984:0.008496:0.004218:0.004823:0.007861:0.007695:0.005004:0.008466:0.005261:0.007846:0.004218:0.005034:0.008859:0.004233:0.007695:0.004188:0.008904:0.003598:0.007241:0.007907:0.008436:0.004218:0.005261:0.007635:0.008466:0.008904:0.007907
 :@0.526423:0.369465:0.530565:0.369465:0.530565:0.355686:0.526423:0.355686:0.004142
min_max_scaler = preprocessing.MinMaxScaler() :@0.120984:0.383718:0.446879:0.383718:0.446879:0.369939:0.120984:0.369939:0.013092:0.003659:0.008436:0.006274:0.013062:0.007695:0.006818:0.006274:0.006410:0.007060:0.007695:0.003598:0.007861:0.005261:0.004203:0.010280:0.004218:0.008889:0.005261:0.007816:0.008889:0.005261:0.008859:0.006984:0.007907:0.006410:0.006470:0.003659:0.008436:0.008904:0.003190:0.013500:0.003810:0.008466:0.013500:0.007846:0.006848:0.008028:0.007075:0.007695:0.003598:0.007861:0.005261:0.004596:0.004836:0.004142
 :@0.120984:0.397971:0.125126:0.397971:0.125126:0.384192:0.120984:0.384192:0.004142
# compute the data minimum and maximum for scaling, then transform. :@0.120984:0.412082:0.606759:0.412082:0.606759:0.398303:0.120984:0.398303:0.008869:0.004233:0.007055:0.008859:0.013092:0.008889:0.008451:0.005034:0.007861:0.004218:0.005034:0.008466:0.007861:0.004218:0.008904:0.007619:0.005034:0.007695:0.004188:0.013092:0.003659:0.008436:0.003659:0.013062:0.008466:0.013092:0.004218:0.007695:0.008436:0.008904:0.004188:0.013092:0.007695:0.006818:0.003659:0.013062:0.008466:0.013092:0.004218:0.004823:0.008859:0.005261:0.004203:0.006244:0.007045:0.007695:0.003598:0.003659:0.008436:0.008904:0.003190:0.004218:0.005034:0.008466:0.008043:0.008647:0.004218:0.005034:0.005261:0.007635:0.008466:0.006410:0.004868:0.008859:0.005261:0.013077:0.003630:0.004142
x_scaled = min_max_scaler.fit_transform(x) :@0.120984:0.426335:0.405960:0.426335:0.405960:0.412556:0.120984:0.412556:0.006848:0.006274:0.006410:0.007060:0.007695:0.003598:0.007861:0.008904:0.004188:0.010280:0.004218:0.013092:0.003659:0.008436:0.006274:0.013062:0.007695:0.006818:0.006274:0.006410:0.007060:0.007695:0.003598:0.007861:0.005261:0.003205:0.004823:0.003659:0.005004:0.006440:0.005231:0.005261:0.007635:0.008466:0.006410:0.004868:0.008859:0.005261:0.013077:0.004626:0.006848:0.004629:0.004142
 :@0.120984:0.440588:0.125126:0.440588:0.125126:0.426809:0.120984:0.426809:0.004142
# optional   change to numpy array :@0.120984:0.454841:0.364033:0.454841:0.364033:0.441062:0.120984:0.441062:0.008869:0.004233:0.008869:0.008889:0.005019:0.003659:0.008859:0.008451:0.007695:0.003598:0.004142:0.007734:0.004233:0.007045:0.008466:0.007695:0.008436:0.008904:0.007831:0.004218:0.005034:0.008859:0.004233:0.008466:0.008466:0.013092:0.008889:0.007241:0.004414:0.007695:0.005201:0.005261:0.007635:0.007574:0.004142
–:@0.193341:0.454841:0.200900:0.454841:0.200900:0.441062:0.193341:0.441062:0.007559
X=np.asarray(x_scaled) :@0.120984:0.468952:0.276349:0.468952:0.276349:0.455173:0.120984:0.455173:0.008874:0.010280:0.008466:0.008889:0.003386:0.007695:0.006410:0.007695:0.005216:0.005261:0.007635:0.007257:0.004626:0.006848:0.006274:0.006410:0.007060:0.007695:0.003598:0.007861:0.008904:0.004881:0.004142
y=np.asarray(dataset.iloc[:,-1]) :@0.120984:0.483229:0.325129:0.483229:0.325129:0.469450:0.120984:0.469450:0.007257:0.010280:0.008466:0.008889:0.003386:0.007695:0.006410:0.007695:0.005216:0.005261:0.007635:0.007257:0.004626:0.008904:0.007816:0.005034:0.007695:0.006410:0.007907:0.005004:0.003417:0.003659:0.003598:0.008859:0.007045:0.004626:0.003220:0.003354:0.006047:0.008058:0.004626:0.004651:0.004142
 :@0.120984:0.497482:0.125126:0.497482:0.125126:0.483703:0.120984:0.483703:0.004142
# split the dataset into train and test. Test size is set at 75% of dataset (10,000 rows) :@0.120984:0.511735:0.682601:0.511735:0.682601:0.497956:0.120984:0.497956:0.008869:0.004233:0.006450:0.008889:0.003613:0.003659:0.005004:0.004218:0.005034:0.008466:0.007861:0.004218:0.008904:0.007619:0.005231:0.007695:0.006410:0.007907:0.005004:0.004218:0.003659:0.008617:0.005034:0.008859:0.004372:0.005034:0.005261:0.007635:0.003659:0.008436:0.004218:0.007846:0.008647:0.008904:0.004188:0.005034:0.007861:0.006410:0.005080:0.003220:0.004218:0.007861:0.007861:0.006410:0.005080:0.004218:0.006410:0.003659:0.006833:0.007907:0.004203:0.003659:0.006410:0.004233:0.006410:0.007907:0.005034:0.004218:0.007695:0.005004:0.004218:0.008058:0.008058:0.012291:0.004218:0.009056:0.004823:0.004218:0.008904:0.007619:0.005034:0.007695:0.006410:0.007907:0.005004:0.004218:0.004626:0.008058:0.008058:0.003220:0.008254:0.008058:0.008058:0.004218:0.005261:0.008859:0.010870:0.006410:0.005088:0.004142
# further details on random_state:  :@0.120984:0.525846:0.355164:0.525846:0.355164:0.512066:0.120984:0.512066:0.008869:0.004233:0.004838:0.008466:0.005261:0.005019:0.008466:0.007861:0.005261:0.004203:0.008904:0.007831:0.005231:0.007695:0.003598:0.003659:0.006410:0.004233:0.008859:0.008481:0.004218:0.005261:0.007635:0.008466:0.008904:0.008859:0.013062:0.006274:0.006410:0.005246:0.007695:0.005004:0.007861:0.003220:0.004544:0.004142
# https://het.as.utexas.edu/HET/Software/Numpy/reference/generated/numpy.random.RandomState.html :@0.120984:0.540099:0.829782:0.540099:0.829782:0.526320:0.120984:0.526320:0.008874:0.004218:0.008466:0.005034:0.005034:0.008889:0.006410:0.003432:0.005851:0.005851:0.008466:0.008043:0.005034:0.003220:0.007695:0.006410:0.003417:0.008466:0.005034:0.008043:0.006848:0.007695:0.006410:0.003235:0.008043:0.008904:0.008436:0.005851:0.010688:0.007846:0.007861:0.005851:0.008028:0.008859:0.004868:0.005034:0.010930:0.007619:0.005261:0.007846:0.005851:0.011475:0.008466:0.013092:0.008889:0.007241:0.005851:0.005261:0.007846:0.004823:0.007861:0.005261:0.008028:0.008466:0.007045:0.007861:0.006032:0.008904:0.007831:0.008466:0.007861:0.005261:0.007831:0.005034:0.007861:0.008904:0.006002:0.008466:0.008466:0.013092:0.008889:0.007241:0.003417:0.005261:0.007635:0.008466:0.008904:0.008859:0.013062:0.003220:0.009041:0.007876:0.008647:0.008904:0.008859:0.013062:0.008028:0.005080:0.007695:0.005004:0.007861:0.003220:0.008647:0.005034:0.013092:0.004319:0.004142
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75, random_state=None) :@0.120984:0.554352:0.707797:0.554352:0.707797:0.540573:0.120984:0.540573:0.008874:0.006274:0.005019:0.005261:0.007635:0.003810:0.008466:0.003220:0.004218:0.008874:0.006274:0.005019:0.007861:0.006637:0.005034:0.003220:0.004218:0.007257:0.006274:0.005019:0.005427:0.007695:0.003598:0.008466:0.003220:0.004218:0.007257:0.006440:0.005034:0.007861:0.006410:0.005080:0.004218:0.010462:0.004218:0.005034:0.005261:0.007635:0.003659:0.008436:0.006274:0.005201:0.007861:0.006410:0.005080:0.006274:0.006410:0.008889:0.003659:0.003779:0.005034:0.004626:0.008874:0.003220:0.004218:0.007257:0.003220:0.004218:0.005034:0.007861:0.006410:0.005080:0.006274:0.006410:0.003659:0.007030:0.007861:0.010462:0.008058:0.003220:0.008254:0.008058:0.003220:0.004218:0.005261:0.007635:0.008466:0.008904:0.008859:0.013062:0.006274:0.006410:0.005049:0.007846:0.005034:0.007861:0.010280:0.011308:0.009041:0.008466:0.007861:0.005348:0.004142
 :@0.120984:0.568605:0.125126:0.568605:0.125126:0.554826:0.120984:0.554826:0.004142
# set TPOT parameters (see Appendix: B for further details) :@0.120984:0.582716:0.516052:0.582716:0.516052:0.568936:0.120984:0.568936:0.008869:0.004233:0.006410:0.007907:0.005034:0.004218:0.007861:0.008466:0.011475:0.007861:0.004218:0.008889:0.007635:0.005261:0.007635:0.013092:0.007861:0.005034:0.007861:0.005261:0.006410:0.004233:0.004626:0.006410:0.007907:0.007861:0.004218:0.009675:0.008889:0.008889:0.007816:0.008626:0.008904:0.003779:0.006869:0.003225:0.004233:0.008663:0.004218:0.004823:0.008859:0.005261:0.004021:0.004823:0.008466:0.005261:0.005019:0.008466:0.007861:0.005261:0.004203:0.008904:0.007831:0.005231:0.007695:0.003598:0.003659:0.006410:0.004740:0.004142
tpot = TPOTClassifier(generations=1, verbosity=2, population_size=100, scoring='accuracy', config_dict='TPOT :@0.120984:0.596969:0.860751:0.596969:0.860751:0.583190:0.120984:0.583190:0.005034:0.008889:0.008859:0.005034:0.004218:0.010280:0.004218:0.007861:0.008466:0.011475:0.007861:0.009267:0.003659:0.007635:0.006410:0.006470:0.003659:0.004792:0.003659:0.007831:0.005261:0.004596:0.008904:0.007831:0.008647:0.007861:0.005261:0.007635:0.005034:0.003810:0.008859:0.008481:0.006410:0.010341:0.008043:0.003220:0.004218:0.007241:0.007907:0.005216:0.008889:0.008859:0.006410:0.003659:0.005231:0.007257:0.010280:0.008254:0.003479:0.004233:0.008889:0.008859:0.008889:0.008436:0.003659:0.007816:0.005034:0.003659:0.009025:0.008466:0.006274:0.006410:0.003659:0.006833:0.007907:0.010235:0.008254:0.008058:0.008254:0.003220:0.004218:0.006410:0.007075:0.008859:0.005261:0.003659:0.008421:0.008904:0.010250:0.003432:0.007695:0.006984:0.007075:0.008466:0.005261:0.007635:0.007045:0.007257:0.003613:0.003220:0.004218:0.007045:0.008859:0.008481:0.004823:0.003659:0.008844:0.006274:0.008844:0.003659:0.006984:0.005080:0.010280:0.003432:0.007861:0.008466:0.011475:0.007861:0.004142
light') :@0.120984:0.611222:0.163022:0.611222:0.163022:0.597443:0.120984:0.597443:0.003659:0.003598:0.008904:0.008436:0.005231:0.003432:0.004636:0.004142
tpot.fit(X_train, y_train) :@0.120984:0.625475:0.275946:0.625475:0.275946:0.611696:0.120984:0.611696:0.005034:0.008889:0.008859:0.005034:0.003220:0.004823:0.003659:0.005004:0.004626:0.008874:0.006440:0.005034:0.005261:0.007635:0.003659:0.008617:0.003220:0.004218:0.007257:0.006274:0.005019:0.005261:0.007831:0.003659:0.008436:0.004977:0.004142
output_score=str(tpot.score(X_test, y_test)) :@0.120984:0.639586:0.409387:0.639586:0.409387:0.625806:0.120984:0.625806:0.008859:0.008481:0.005034:0.008889:0.008632:0.005034:0.006274:0.006410:0.007060:0.008859:0.005261:0.007846:0.010280:0.006410:0.005080:0.005261:0.004596:0.005034:0.008889:0.009041:0.005034:0.003220:0.006410:0.007075:0.008859:0.005261:0.007846:0.004626:0.008874:0.006440:0.005034:0.007861:0.006410:0.005080:0.003220:0.004218:0.007257:0.006440:0.005034:0.007861:0.006410:0.005080:0.004626:0.004851:0.004142
 :@0.120984:0.653839:0.125126:0.653839:0.125126:0.640060:0.120984:0.640060:0.004142
# export TPOT results as python script :@0.120984:0.668092:0.378748:0.668092:0.378748:0.654313:0.120984:0.654313:0.008874:0.004218:0.007861:0.006848:0.008889:0.008859:0.005261:0.005004:0.004218:0.007861:0.008466:0.011475:0.007861:0.004218:0.005261:0.007846:0.006410:0.008511:0.003659:0.005004:0.006410:0.004263:0.007695:0.006410:0.004218:0.008889:0.007241:0.005231:0.008466:0.009056:0.008466:0.004218:0.006410:0.007075:0.005261:0.003613:0.008889:0.005204:0.004142
tpot.export('tpot_creditcard_pipeline.py') :@0.120984:0.682381:0.395276:0.682381:0.395276:0.668602:0.120984:0.668602:0.005034:0.008889:0.008859:0.005034:0.003220:0.008043:0.006848:0.008889:0.008859:0.005261:0.005004:0.004626:0.003613:0.005034:0.008889:0.008859:0.005034:0.006274:0.007015:0.005261:0.007846:0.008904:0.003779:0.005034:0.007045:0.007695:0.005201:0.008904:0.006213:0.008889:0.003795:0.008889:0.007846:0.003659:0.003598:0.008466:0.008043:0.003220:0.008889:0.007241:0.003432:0.005012:0.004142
 :@0.120984:0.696634:0.125126:0.696634:0.125126:0.682855:0.120984:0.682855:0.004142
# print the TPOT result :@0.120984:0.710744:0.276349:0.710744:0.276349:0.696965:0.120984:0.696965:0.008874:0.004218:0.008889:0.005261:0.003583:0.008466:0.005034:0.004218:0.005034:0.008647:0.007861:0.004287:0.007861:0.008466:0.011475:0.007876:0.004233:0.005261:0.007846:0.006410:0.008511:0.003659:0.005251:0.004142
print(tpot.score(X_test, y_test)) :@0.120984:0.724998:0.326943:0.724998:0.326943:0.711218:0.120984:0.711218:0.008889:0.005261:0.003583:0.008466:0.005034:0.004626:0.005034:0.008889:0.009041:0.005034:0.003220:0.006410:0.007075:0.008859:0.005261:0.007846:0.004626:0.008874:0.006274:0.005019:0.007861:0.006637:0.005034:0.003220:0.004218:0.007257:0.006274:0.005019:0.007861:0.006637:0.005034:0.004626:0.004816:0.004142
 :@0.120984:0.739251:0.125126:0.739251:0.125126:0.725472:0.120984:0.725472:0.004142
# PDI output fields which are defined in a dataframe which is mapped to a PDI output field: model_df :@0.120984:0.753504:0.798505:0.753504:0.798505:0.739725:0.120984:0.739725:0.008869:0.004233:0.008466:0.010673:0.004021:0.004253:0.008859:0.008481:0.005034:0.008889:0.008451:0.005034:0.004218:0.004823:0.003659:0.007831:0.003659:0.008844:0.006469:0.004233:0.010930:0.008421:0.003659:0.006984:0.008511:0.004218:0.007695:0.005201:0.007861:0.004218:0.008904:0.007831:0.004823:0.003659:0.008436:0.007861:0.008904:0.004188:0.003659:0.008436:0.004218:0.007695:0.004188:0.008904:0.007619:0.005034:0.007695:0.004792:0.005261:0.007635:0.013092:0.007861:0.004218:0.010930:0.008421:0.003659:0.006984:0.008511:0.004218:0.003659:0.006410:0.004233:0.013092:0.007695:0.008829:0.008889:0.007846:0.008904:0.004188:0.005034:0.008859:0.004233:0.007695:0.004188:0.008466:0.010673:0.004021:0.004233:0.008859:0.008481:0.005034:0.008889:0.008451:0.005034:0.004218:0.004823:0.003659:0.007831:0.003659:0.008844:0.003220:0.004218:0.013092:0.008859:0.008904:0.007831:0.003659:0.006213:0.008904:0.005214:0.004142
model_name=[x[0] for x in tpot.evaluated_individuals_.items()] :@0.120984:0.767615:0.537217:0.767615:0.537217:0.753835:0.120984:0.753835:0.013092:0.008859:0.008904:0.007831:0.003659:0.006213:0.008466:0.007695:0.013047:0.007861:0.010280:0.004626:0.006848:0.004626:0.008058:0.004626:0.004218:0.004823:0.008859:0.005261:0.004203:0.006848:0.004218:0.003659:0.008436:0.004218:0.005034:0.008889:0.008859:0.005034:0.003220:0.007861:0.007241:0.007695:0.003795:0.008466:0.007695:0.005004:0.008043:0.008904:0.006213:0.003659:0.008436:0.009056:0.003659:0.007241:0.003613:0.008904:0.008617:0.007695:0.003907:0.006410:0.006274:0.003281:0.003583:0.005231:0.007861:0.013092:0.006410:0.004656:0.004430:0.004687:0.004142
model_gen=[x[1]['generation'] for x in tpot.evaluated_individuals_.items()] :@0.120984:0.781868:0.614016:0.781868:0.614016:0.768088:0.120984:0.768088:0.013092:0.008859:0.008904:0.007831:0.003659:0.006213:0.008904:0.007831:0.008466:0.010280:0.004626:0.006848:0.004823:0.008058:0.004626:0.004626:0.003432:0.008904:0.007831:0.008466:0.007861:0.005261:0.007831:0.005034:0.003659:0.008859:0.008632:0.003432:0.004626:0.004218:0.004823:0.008859:0.005261:0.004203:0.006848:0.004218:0.003659:0.008436:0.004218:0.005034:0.008889:0.008859:0.005034:0.003220:0.007861:0.007241:0.007695:0.003613:0.008466:0.007846:0.005034:0.007861:0.008904:0.006395:0.003659:0.008436:0.008904:0.003598:0.007241:0.003825:0.008904:0.008617:0.007695:0.003598:0.006410:0.006274:0.003281:0.003583:0.005034:0.007861:0.013092:0.006410:0.004656:0.004626:0.005011:0.004142
model_mut=[x[1]['mutation_count'] for x in tpot.evaluated_individuals_.items()] :@0.120984:0.796121:0.647931:0.796121:0.647931:0.782342:0.120984:0.782342:0.013092:0.008859:0.008904:0.007831:0.003659:0.006213:0.013092:0.008466:0.005034:0.010280:0.004626:0.006848:0.004626:0.008058:0.004626:0.004626:0.003432:0.013092:0.008466:0.005034:0.007846:0.005034:0.003659:0.008859:0.008451:0.006274:0.007015:0.009056:0.008466:0.008466:0.005231:0.003432:0.004626:0.004218:0.004823:0.008859:0.005261:0.004203:0.006848:0.004218:0.003659:0.008436:0.004218:0.005034:0.008889:0.008859:0.005034:0.003220:0.007861:0.007241:0.007695:0.003613:0.008466:0.007846:0.005034:0.007861:0.008904:0.006213:0.003810:0.008647:0.008904:0.003598:0.007241:0.003659:0.008859:0.008466:0.007695:0.003598:0.006410:0.006470:0.003220:0.003659:0.005004:0.007861:0.013092:0.006410:0.004656:0.004626:0.005122:0.004142
model_cross=[x[1]['crossover_count'] for x in tpot.evaluated_individuals_.items()] :@0.120984:0.810374:0.657606:0.810374:0.657606:0.796595:0.120984:0.796595:0.013092:0.008859:0.008904:0.007831:0.003659:0.006213:0.007045:0.005261:0.008859:0.006410:0.006470:0.010280:0.004626:0.006848:0.004626:0.008058:0.004626:0.004626:0.003432:0.007045:0.005261:0.008859:0.006410:0.006470:0.008859:0.007241:0.007907:0.005261:0.006213:0.006848:0.008859:0.008481:0.008466:0.005231:0.003432:0.004626:0.004218:0.004823:0.008859:0.005261:0.004203:0.006848:0.004218:0.003659:0.008436:0.004218:0.005034:0.008889:0.008859:0.005034:0.003220:0.007861:0.007241:0.007695:0.003613:0.008466:0.007846:0.005034:0.007861:0.008904:0.006213:0.003810:0.008466:0.008904:0.003598:0.007241:0.003659:0.008859:0.008647:0.007695:0.003598:0.006410:0.006274:0.003281:0.003779:0.005034:0.007861:0.013092:0.006410:0.004656:0.004626:0.004865:0.004142
model_predec=[x[1]['predecessor'] for x in tpot.evaluated_individuals_.items()] :@0.120984:0.824485:0.642690:0.824485:0.642690:0.810705:0.120984:0.810705:0.013092:0.008859:0.008904:0.007831:0.003643:0.006274:0.008844:0.005261:0.007846:0.008904:0.007831:0.007045:0.010280:0.004626:0.006848:0.004626:0.008058:0.004626:0.004626:0.003432:0.008889:0.005261:0.007816:0.008904:0.007831:0.007045:0.007861:0.006637:0.006410:0.008889:0.005261:0.003402:0.004626:0.004218:0.004823:0.008859:0.005049:0.004218:0.006848:0.004218:0.003659:0.008436:0.004218:0.005034:0.008889:0.008859:0.005034:0.003220:0.007861:0.007241:0.007695:0.003795:0.008466:0.007695:0.005004:0.007861:0.009056:0.006274:0.003598:0.008647:0.008904:0.003598:0.007241:0.003659:0.008859:0.008466:0.007695:0.003598:0.006410:0.006470:0.003220:0.003659:0.005004:0.007861:0.013092:0.006410:0.004656:0.004626:0.005066:0.004142
model_opp=[x[1]['operator_count'] for x in tpot.evaluated_individuals_.items()] :@0.120984:0.838738:0.645109:0.838738:0.645109:0.824958:0.120984:0.824958:0.013092:0.008859:0.008904:0.007831:0.003659:0.006213:0.008859:0.008889:0.008889:0.010250:0.004626:0.006848:0.004626:0.008058:0.004626:0.004626:0.003432:0.008859:0.008889:0.007846:0.005261:0.007635:0.005034:0.008859:0.005261:0.006274:0.006984:0.009086:0.008466:0.008466:0.005231:0.003432:0.004626:0.004218:0.004823:0.008859:0.005261:0.004203:0.006848:0.004218:0.003659:0.008436:0.004218:0.005034:0.008889:0.008859:0.005034:0.003220:0.007861:0.007241:0.007695:0.003613:0.008466:0.007846:0.005034:0.007861:0.008904:0.006213:0.003810:0.008647:0.008904:0.003598:0.007241:0.003659:0.008859:0.008466:0.007695:0.003598:0.006410:0.006470:0.003220:0.003659:0.005004:0.007861:0.013092:0.006410:0.004656:0.004626:0.005081:0.004142
model_cv=[str(y[1]['internal_cv_score']) for y in tpot.evaluated_individuals_.items()] :@0.120984:0.852991:0.669499:0.852991:0.669499:0.839212:0.120984:0.839212:0.013092:0.008859:0.008904:0.007831:0.003659:0.006213:0.007045:0.007241:0.010295:0.004626:0.006410:0.005080:0.005261:0.004596:0.007257:0.004626:0.008058:0.004626:0.004626:0.003432:0.003659:0.008436:0.005034:0.007861:0.005261:0.008632:0.007695:0.003598:0.006274:0.007015:0.007241:0.006274:0.006410:0.007075:0.008859:0.005261:0.007846:0.003432:0.004626:0.004626:0.004036:0.004823:0.008859:0.005261:0.004203:0.007257:0.004218:0.003659:0.008436:0.004218:0.005034:0.008889:0.008859:0.005034:0.003220:0.007861:0.007241:0.007695:0.003613:0.008466:0.007846:0.005034:0.007861:0.009056:0.006274:0.003598:0.008466:0.008904:0.003598:0.007241:0.003659:0.009041:0.008466:0.007695:0.003598:0.006410:0.006274:0.003281:0.003779:0.005034:0.007861:0.013092:0.006410:0.004656:0.004626:0.004875:0.004142
model_list=list(zip(model_name,model_gen,model_mut,model_cross,model_predec,model_opp,model_cv)) :@0.120984:0.867268:0.829782:0.867268:0.829782:0.853488:0.120984:0.853488:0.013092:0.008859:0.008904:0.007831:0.003659:0.006213:0.003659:0.003598:0.006410:0.005080:0.010280:0.003659:0.003598:0.006665:0.005034:0.004626:0.006833:0.003659:0.008889:0.004566:0.013122:0.008859:0.008904:0.007831:0.003659:0.006213:0.008466:0.007695:0.013258:0.007861:0.003220:0.013092:0.008859:0.008904:0.007831:0.003659:0.006213:0.008904:0.008012:0.008466:0.003220:0.013092:0.008859:0.008904:0.007831:0.003659:0.006213:0.013092:0.008647:0.005034:0.003220:0.013092:0.008859:0.008904:0.008028:0.003659:0.006213:0.007045:0.005261:0.008859:0.006410:0.006470:0.003220:0.013092:0.008859:0.008904:0.007831:0.003659:0.006213:0.008889:0.005261:0.007816:0.008904:0.007831:0.007045:0.003220:0.013092:0.008859:0.008904:0.007831:0.003659:0.006213:0.009056:0.008889:0.008889:0.003190:0.013092:0.008859:0.008904:0.007831:0.003659:0.006213:0.007045:0.007241:0.004641:0.005122:0.004142
model_df=pd.DataFrame(model_list,columns=['pipe','generation','mutation','crossover','predecessor','operator','cv:@0.120984:0.881378:0.875927:0.881378:0.875927:0.867599:0.120984:0.867599:0.013092:0.008859:0.008904:0.007831:0.003659:0.006213:0.008904:0.004792:0.010280:0.008889:0.008844:0.003220:0.010673:0.007695:0.005004:0.007695:0.007408:0.005261:0.007635:0.013092:0.007861:0.004626:0.013092:0.008859:0.008904:0.007831:0.003659:0.006213:0.003659:0.003598:0.006410:0.005080:0.003220:0.007045:0.008859:0.003825:0.008466:0.013092:0.008466:0.006410:0.010341:0.004596:0.003432:0.008889:0.003613:0.008889:0.007846:0.003613:0.003220:0.003432:0.008904:0.008012:0.008466:0.007861:0.005261:0.007831:0.005231:0.003659:0.008859:0.008451:0.003432:0.003220:0.003432:0.013092:0.008647:0.005034:0.007695:0.005185:0.003659:0.008859:0.008451:0.003432:0.003417:0.003432:0.007045:0.005261:0.008859:0.006410:0.006470:0.008859:0.007241:0.007907:0.005261:0.003386:0.003220:0.003432:0.008889:0.005261:0.008012:0.008904:0.007831:0.007045:0.007861:0.006410:0.006470:0.008859:0.005261:0.003417:0.003220:0.003432:0.008859:0.008889:0.007846:0.005261:0.007831:0.005034:0.008859:0.005261:0.003417:0.003220:0.003432:0.007045:0.007241
']) :@0.120984:0.895631:0.137825:0.895631:0.137825:0.881852:0.120984:0.881852:0.003432:0.004626:0.004641:0.004142
 :@0.120984:0.911773:0.125175:0.911773:0.125175:0.898660:0.120984:0.898660:0.004191